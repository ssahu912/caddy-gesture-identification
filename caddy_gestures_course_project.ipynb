{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "caddy-gestures-course-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssahu912/caddy-gesture-identification/blob/main/caddy_gestures_course_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVDueJdOanqf",
        "outputId": "387993ac-2286-4cbc-a405-d4971995d2dd"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1FdIwG5tk-mNrei-SVpC6SEbi9VAhL-pY')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████                           | 10kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVuq_uilanqm"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfeRBYDSm_Y-"
      },
      "source": [
        "project_name='caddy-gestures-course-project'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSex6sKaa9Op"
      },
      "source": [
        "# Exploring CADDY Underwater Gestures Dataset\r\n",
        "### Human-Robot Interaction (HRI) for Diver and AUVs activities\r\n",
        "This is an open access dataset distributed under the Creative Commons Attribution License which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited (CC BY 4.0).\r\n",
        "<p>\r\n",
        "The dataset can be downloaded from the <a href=\"http://www.caddian.eu//assets/caddy-gestures-TMP/CADDY_gestures_complete_v2_release.zip\">link</a>.\r\n",
        "<p>\r\n",
        "Choosing this dataset of hand gestures used by divers underwater to provide instructtions in 8 different scenarios. The scenarios involved in this dataset are as follows: \r\n",
        "<table><tr>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/biograd-A/true_positives/raw/biograd-A_00162_left.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/biograd-B/true_positives/raw/biograd-B_00032_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/biograd-C/true_positives/raw/biograd-C_00098_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/brodarski-A/true_positives/raw/brodarski-A_00018_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "</tr>\r\n",
        "<td>BioGrad-A</td>\r\n",
        "<td>BioGrad-B</td>\r\n",
        "<td>BioGrad-C</td>\r\n",
        "<td>Brodarski-A</td>\r\n",
        "</tr>\r\n",
        "<tr>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/brodarski-B/true_positives/raw/brodarski-B_00029_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/brodarski-C/true_positives/raw/brodarski-C_00006_left.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/brodarski-D/true_positives/raw/brodarski-D_00032_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "<td> <img src=\"http://www.caddian.eu//assets/caddy-gestures-TMP/genova-A/true_positives/raw/genova-A_00032_right.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\r\n",
        "</tr>\r\n",
        "</tr>\r\n",
        "<td>Brodarski-B</td>\r\n",
        "<td>Brodarski-C</td>\r\n",
        "<td>Brodarski-D</td>\r\n",
        "<td>Genova-A</td>\r\n",
        "</tr>\r\n",
        "</table>\r\n",
        "It is a classification type problem where given an image of the person with the gesture the machine will identify the gesture meaning in multiple scenarios.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Bp4SPthSKg"
      },
      "source": [
        "If you wish to upload the data on the drive then use this code to mount the drive so that it is available to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxjT2lhnjEFt",
        "outputId": "2b22a377-17e6-4a15-f2c0-7151013db230"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXS_KpkMj93W"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import zipfile\r\n",
        "from torchvision.datasets.utils import download_url\r\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOQAWTYuhCTa"
      },
      "source": [
        "If you wish to download the data set and load it while running the notebook and do not want ot upload it to your drive please uncomment the below cell and execute. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzEevkfCanqm"
      },
      "source": [
        "# # Dowload the dataset\r\n",
        "# dataset_url = \"http://www.caddian.eu//assets/caddy-gestures-TMP/CADDY_gestures_complete_v2_release.zip\"\r\n",
        "# download_url(dataset_url, '.')\r\n",
        "# # Extract from downloaded archive\r\n",
        "# with zipfile.ZipFile('./CADDY_gestures_complete_v2_release.zip', 'r') as zip_ref:\r\n",
        "#     zip_ref.extractall('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfq_coKyj3rd"
      },
      "source": [
        "# Extract from drive archive\r\n",
        "with zipfile.ZipFile('./drive/MyDrive/CADDY_gestures_complete_v2_release.zip', 'r') as zip_ref:\r\n",
        "    zip_ref.extractall('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWVb2HbwjTJZ"
      },
      "source": [
        "## Data Analysis\r\n",
        "\r\n",
        "Let's explore the data!\r\n",
        "\r\n",
        "Looking at the folder structure we see that we have 8 folders for 8 scenarios which contain raw images of multiple gestures captured by the ledt and right stereo.\r\n",
        "<p>\r\n",
        "The folder structure of the data is something like this:\r\n",
        "<p>\r\n",
        "data => biograd-A => true_positives => raw => image1, image2 ... imageN\r\n",
        "\r\n",
        "Let's take a look what's inside the the csv files and how are they structured!!\r\n",
        "(We'll be looking at the true positives only for the scope of the project.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVsoEsOFg0Bh"
      },
      "source": [
        "# Importing required EDA tools\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "BXE3rwgekdqb",
        "outputId": "c9c5e2be-173f-4ca6-a524-662c02a1f87b"
      },
      "source": [
        "dataFromCSV = pd.read_csv('./data/CADDY_gestures_complete_v2_release/CADDY_gestures_all_true_positives_release_v2.csv', index_col='index')\r\n",
        "dataFromCSV.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scenario</th>\n",
              "      <th>stereo left</th>\n",
              "      <th>stereo right</th>\n",
              "      <th>label name</th>\n",
              "      <th>label id</th>\n",
              "      <th>roi left</th>\n",
              "      <th>roi right</th>\n",
              "      <th>synthetic</th>\n",
              "      <th>iqa_mdm_entropy</th>\n",
              "      <th>iqa_mdm_d</th>\n",
              "      <th>iqa_mdm_dcomp</th>\n",
              "      <th>distortion</th>\n",
              "      <th>param 1</th>\n",
              "      <th>param 2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>biograd-A</td>\n",
              "      <td>/biograd-A/true_positives/raw/biograd-A_00000_...</td>\n",
              "      <td>/biograd-A/true_positives/raw/biograd-A_00000_...</td>\n",
              "      <td>num_delimiter</td>\n",
              "      <td>10</td>\n",
              "      <td>[237,236,54,65]</td>\n",
              "      <td>[155,236,54,65]</td>\n",
              "      <td>0</td>\n",
              "      <td>6.971026</td>\n",
              "      <td>0.957653</td>\n",
              "      <td>0.902</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>biograd-A</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_00/biogr...</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_00/biogr...</td>\n",
              "      <td>num_delimiter</td>\n",
              "      <td>10</td>\n",
              "      <td>[237,236,54,65]</td>\n",
              "      <td>[155,236,54,65]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blur</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>biograd-A</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_01/biogr...</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_01/biogr...</td>\n",
              "      <td>num_delimiter</td>\n",
              "      <td>10</td>\n",
              "      <td>[237,236,54,65]</td>\n",
              "      <td>[155,236,54,65]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blur</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>biograd-A</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_02/biogr...</td>\n",
              "      <td>/biograd-A/true_positives/blurred/dir_02/biogr...</td>\n",
              "      <td>num_delimiter</td>\n",
              "      <td>10</td>\n",
              "      <td>[237,236,54,65]</td>\n",
              "      <td>[155,236,54,65]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blur</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>biograd-A</td>\n",
              "      <td>/biograd-A/true_positives/noisy/dir_00/biograd...</td>\n",
              "      <td>/biograd-A/true_positives/noisy/dir_00/biograd...</td>\n",
              "      <td>num_delimiter</td>\n",
              "      <td>10</td>\n",
              "      <td>[237,236,54,65]</td>\n",
              "      <td>[155,236,54,65]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>channel noise</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        scenario  ... param 2\n",
              "index             ...        \n",
              "0      biograd-A  ...     NaN\n",
              "1      biograd-A  ...     NaN\n",
              "2      biograd-A  ...     NaN\n",
              "3      biograd-A  ...     NaN\n",
              "4      biograd-A  ...     NaN\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwVHdZgVkebr",
        "outputId": "05102a5a-f561-4e76-93ba-d3b47c124750"
      },
      "source": [
        "dataFromCSV.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 92390 entries, 0 to 92389\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   scenario         92390 non-null  object \n",
            " 1   stereo left      92390 non-null  object \n",
            " 2   stereo right     92390 non-null  object \n",
            " 3   label name       92390 non-null  object \n",
            " 4   label id         92390 non-null  int64  \n",
            " 5   roi left         91790 non-null  object \n",
            " 6   roi right        91440 non-null  object \n",
            " 7   synthetic        92390 non-null  int64  \n",
            " 8   iqa_mdm_entropy  9239 non-null   float64\n",
            " 9   iqa_mdm_d        9239 non-null   float64\n",
            " 10  iqa_mdm_dcomp    9239 non-null   float64\n",
            " 11  distortion       83151 non-null  object \n",
            " 12  param 1          83151 non-null  object \n",
            " 13  param 2          18478 non-null  float64\n",
            "dtypes: float64(4), int64(2), object(8)\n",
            "memory usage: 10.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c9lGiiFli0P"
      },
      "source": [
        "For the scope of the project where we are classifying the gestures we would only need the label name of the the image from the CSV.\r\n",
        "<p>\r\n",
        "Also a point worth noting is not all the images are present in the data set as mentioned in CSV. If we look closely inside each and every scenario there are 2 folders \"true_positives\" and \"true_neagtives\", and inside each of them there's only one folder called \"raw\". This means that only raw images are present and not the distorted ones.\r\n",
        "<p>\r\n",
        "Hence we'll be working on the raw set of images which are around 18,400 which is a pretty decent data size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErHrXCW6pXkF"
      },
      "source": [
        "Let's idenetify how many different gestures are available in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHkMgAMakeWi",
        "outputId": "9b9ee86d-ab7e-4049-8715-7b4b5409b5f4"
      },
      "source": [
        "classes = dataFromCSV[\"label name\"].unique()\r\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['num_delimiter', 'five', 'end_comm', 'start_comm', 'one', 'two',\n",
              "       'three', 'four', 'up', 'down', 'backwards', 'mosaic', 'boat',\n",
              "       'carry', 'here', 'photo'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxltmpbxkeOx",
        "outputId": "33d817b5-fccb-4d3d-c48e-116120b7dc56"
      },
      "source": [
        "len(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LylATjTVpllb"
      },
      "source": [
        "We see that we have 16 unique classes hence we have to categorize the images into 16 classes.(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9kFIGU4p3sz"
      },
      "source": [
        "### Data Cleaning \r\n",
        "\r\n",
        "As we saw earlier we have a lot of missing and junk data which we need to filter out, or we can say we need to extract the useful data from the CSV and map them with the images.\r\n",
        "<p>\r\n",
        "So let's create another CSV which can help map the raw data image paths with their labels.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6XzTX2ApxML"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FInzuH_Kl0_O"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcwofBoUnJwz"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "bSlxrjNCnNqx",
        "outputId": "da10fd2a-e9a7-41e5-86ad-5a696dbadff3"
      },
      "source": [
        "jovian.commit(project=project_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/shubham912sahu/caddy-gestures-course-project\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/shubham912sahu/caddy-gestures-course-project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXTDgEJ7nOy8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}